{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de9fdfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up GPU rendering.\n",
    "import distutils.util\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# For Ubuntu\n",
    "# Configure MuJoCo to use the EGL rendering backend (requires GPU)\n",
    "#print('Setting environment variable to use GPU rendering:')\n",
    "#%env MUJOCO_GL=egl\n",
    "\n",
    "# For mac\n",
    "os.environ[\"MUJOCO_GL\"] = \"cgl\"   # macOS\n",
    "\n",
    "# Check if installation was succesful.\n",
    "try:\n",
    "  print('Checking that the installation succeeded:')\n",
    "  import mujoco\n",
    "  mujoco.MjModel.from_xml_string('<mujoco/>')\n",
    "except Exception as e:\n",
    "  raise e from RuntimeError(\n",
    "      'Something went wrong during installation. Check the shell output above '\n",
    "      'for more information.\\n'\n",
    "      'If using a hosted Colab runtime, make sure you enable GPU acceleration '\n",
    "      'by going to the Runtime menu and selecting \"Choose runtime type\".')\n",
    "\n",
    "print('Installation successful.')\n",
    "\n",
    "# Other imports and helper functions\n",
    "import time\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "# Graphics and plotting.\n",
    "print('Installing mediapy:')\n",
    "!command -v ffmpeg >/dev/null || (apt update && apt install -y ffmpeg)\n",
    "!pip install -q mediapy\n",
    "import mediapy as media\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# More legible printing from numpy.\n",
    "np.set_printoptions(precision=3, suppress=True, linewidth=100)\n",
    "\n",
    "from IPython.display import clear_output\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9594817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"MUJOCO_GL\"] = \"cgl\"\n",
    "\n",
    "# import mujoco\n",
    "# m = mujoco.MjModel.from_xml_string(\"<mujoco/>\")\n",
    "# print(\"Mujoco loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7143868e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"show_images\" style=\"border-spacing:0px;\"><tr><td style=\"padding:1px;\"><img width=\"320\" height=\"240\" style=\"image-rendering:auto; object-fit:cover;\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAUAAAADwCAIAAAD+Tyo8AAAEp0lEQVR4nO3az27cRBwH8J+3JRGoLRzg0EoIeimXIuDEA/AAXDjyKLwE4saVZ0GIUxEnhIpy4lJQWwit1JbdQR7bs/6zm6ZJVdfl8+k2sX+ZsSe7+/XY8UYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACwXNXcA+DVdhhxcO3aF5cv34hIKUVE/b/+lpdTitu3v5p7kAt2ce4B8Mq7fOXKzUuXPigBnnzl7Fbn6AvnVFVOAc9HgJmF6D4fAsyLJrrP0VKvgT+LuJkPP/1rqDT82l9oljfDhf5jM6yPVksxnfhouox2Oh1Pf3U67NGvs3Nh2nH608atT2JWj+Le8bBSjUc68wijfs2OIv6OJVpegN+O+K5+X8ThapUmR/VBMKpqELBudbP/a72Q0qZfyX9nWTf1qkp5td+g3Wauj5PfFUeHkn2R3hfmnRHdeZyauvVxzO04fmiXqqr54/PQ/COMegxHET/mN9aiLC/AX+Yn+Y3V6sJqVXUXU+27oqr6SY6c2FGSS7r602kJaj+3g2JebYJawrndTkrNLsa57fa7TW93I+X80d03t4+9FS+Nydz78oxwE/FhxEcR38SyLCzA1/LzvIlYd+Esh/TBao5xm5Zu2hzNgYOZOaVNSk3gm5ZVfqxypX7fVdWqm4TL0aGOdzlG9CJ6wjl8Wa3K+J8xtDvbnBDgw1nikfK/TvX+k/hzb9uDNw/2dTzt3tKzdGle0VGvFOvH6ziOuJ6n4uVYWIA/jXgY8VrExcNa+0mUHIZVM/fmUJXI1T/qVaILXjtRd9N1e+HaNat6ldKsvX5uIj3sWLbWP6XfprQbQFvMvfqrzZlls69S326pDKNfKQeprrjzLVxFXL9xYouhNjzlGJaGxX5luLWm0lSrqLarudnhT/Urtc/Vd6+mSKNe+yo77yCn/p3lScf+CMcde1u+e+du/amT12NZFhbg3/LVyr8Rq4ODCyVIvdPm1Wr7d/U2EvlSuSSgfesPT7xL2LbNurPxbTFXyovfRn0YtnJ7ZBC5bkhVbwDTQ0DbsWvTBnuYu2an+2bjfrOntJjYMfOlycw2qYwTkr9t6muLgfuffz0aTAlbf0Nl4029Xh/tblhJXbfRIEcDaLc8bDVok+LBwwft2N6JZVlYgI8j7kQ8jvjn+Lg66w2KMn1t+5X6ib123rtML/DOyTOfXEYc/Rov0pk/WnXajsPjWTpdr6c226w38STqx8+xLAsL8FG+dXQ/4uJ6/Qrfwj5jCHZ5dO9M3f5vt2pTnhZ+iTjb0zWfhQU4Ir7NV8LXfQbllP6aewCLsI54L+L7WJylHmmvyPDpzP1BjiVIEX9E/D73MAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4iXzH+fBZA4Ej1wZAAAAAElFTkSuQmCC\"/></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "planar_arm = '''\n",
    "<mujoco>\n",
    "  <option timestep=\"0.001\" gravity=\"0 0 -9.81\">\n",
    "    <flag contact=\"enable\"/>\n",
    "  </option>\n",
    "  \n",
    "  <default>\n",
    "    <geom type=\"capsule\" size=\"0.05\"/>\n",
    "    <joint type=\"hinge\" axis=\"0 0 1\"/>\n",
    "  </default>\n",
    "\n",
    "  <worldbody>\n",
    "    <!-- Lighting and camera -->\n",
    "    <light pos=\"0 -0.4 1\"/>\n",
    "    <camera name=\"fixed\" pos=\"1 -3 0\" xyaxes=\"1 0 0 0 0 1\"/>\n",
    "    \n",
    "    <!-- Arm base -->\n",
    "    <body name=\"base\" pos=\"0 0 0\">\n",
    "      <!-- First link -->\n",
    "      <body name=\"link1\" pos=\"0 0 0\">\n",
    "        <joint name=\"joint1\"/>\n",
    "        <geom fromto=\"0 0 0 1 0 0\" rgba=\"1 0 0 1\"/>\n",
    "        \n",
    "        <!-- Second link -->\n",
    "        <body name=\"link2\" pos=\"1 0 0\">\n",
    "          <joint name=\"joint2\"/>\n",
    "          <geom fromto=\"0 0 0 1 0 0\" rgba=\"0 1 0 1\"/>\n",
    "        </body>\n",
    "      </body>\n",
    "    </body>\n",
    "\n",
    "    <!-- Static block -->\n",
    "    <body name=\"block\" pos=\"1.5 0 0.05\">\n",
    "      <geom type=\"box\" size=\"0.05 0.05 0.05\" rgba=\"0 0 1 1\" density=\"1000\" friction=\"1 0.5 0.5\"/>\n",
    "    </body>\n",
    "  </worldbody>\n",
    "\n",
    "  <actuator>\n",
    "    <motor joint=\"joint1\" gear=\"1\"/>\n",
    "    <motor joint=\"joint2\" gear=\"1\"/>\n",
    "  </actuator>\n",
    "</mujoco>\n",
    "'''\n",
    "model = mujoco.MjModel.from_xml_string(planar_arm)\n",
    "data = mujoco.MjData(model)\n",
    "height = 240\n",
    "width = 320\n",
    "\n",
    "with mujoco.Renderer(model, height, width) as renderer:\n",
    "  mujoco.mj_forward(model, data)\n",
    "  renderer.update_scene(data, camera=\"fixed\")\n",
    "\n",
    "  media.show_image(renderer.render())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9ba745",
   "metadata": {},
   "source": [
    "# For Ubuntu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dddcf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import robosuite as suite\n",
    "# import numpy as np\n",
    "\n",
    "# # Create environment with Franka rob1t\n",
    "# env = suite.make(\n",
    "#     env_name=\"Lift\",\n",
    "#     robots=\"Panda\",\n",
    "#     has_renderer=True,\n",
    "#     has_offscreen_renderer=False,\n",
    "#     use_camera_obs=False\n",
    "# )\n",
    "\n",
    "# # Reset the environment\n",
    "# obs = env.reset()\n",
    "# env.render()  # Render the initial state\n",
    "\n",
    "# # Get cube position from observation\n",
    "# cube_pos = obs['cube_pos']\n",
    "# print(\"Cube position:\", cube_pos)\n",
    "\n",
    "# # Define target positions for lifting the cube:\n",
    "# # Stage 1: Move above the cube\n",
    "# above_cube_pos = cube_pos.copy()\n",
    "# above_cube_pos[2] += 0.1  # Position 10cm above the cube\n",
    "\n",
    "# # Stage 2: Move down to grasp the cube\n",
    "# grasp_pos = cube_pos.copy()\n",
    "# grasp_pos[2] -= 0.01  # Move slightly down to grasp\n",
    "\n",
    "# # Stage 3: Lift the cube\n",
    "# lift_pos = cube_pos.copy()\n",
    "# lift_pos[2] += 0.5  # Lift 20cm above the table\n",
    "# #lift_pos[0] += 0.5  # Lift 20cm above the table\n",
    "\n",
    "# print(f\"Above cube target: {above_cube_pos}\")\n",
    "# print(f\"Grasp position: {grasp_pos}\")\n",
    "# print(f\"Lift position: {lift_pos}\")\n",
    "\n",
    "# # Control gains\n",
    "# kp = 5.0  # Position gain\n",
    "# gripper_close_steps = 50  # Steps over which to close gripper gradually\n",
    "# kd = 1.0  # Velocity gain\n",
    "\n",
    "# # Run the simulation\n",
    "# done = False\n",
    "# step_count = 0\n",
    "# max_steps = 500\n",
    "# current_stage = 1\n",
    "# grasped = False\n",
    "\n",
    "\n",
    "# while step_count < max_steps:\n",
    "#     current_eef = obs['robot0_eef_pos']\n",
    "#     current_cube_pos = obs['cube_pos']\n",
    "\n",
    "#     # Determine target\n",
    "#     if current_stage == 1:\n",
    "#         target = above_cube_pos\n",
    "#         if np.linalg.norm(current_eef - target) < 0.02:\n",
    "#             current_stage = 2\n",
    "#             print(\"Above cube reached, moving to grasp\")\n",
    "#     elif current_stage == 2:\n",
    "#         target = grasp_pos\n",
    "#         if np.linalg.norm(current_eef - target) < 0.01:\n",
    "#             current_stage = 3\n",
    "#             print(\"ready to grasp\")\n",
    "#     elif current_stage == 3:\n",
    "#         target = grasp_pos\n",
    "#         if action[-1] > 0.5:\n",
    "#             grasped = True\n",
    "#         if np.linalg.norm(current_eef - target) < 0.01 and grasped:\n",
    "#             current_stage = 4 \n",
    "#             print(\"Cube grasped, lifting\")\n",
    "#     else:\n",
    "#         target = lift_pos\n",
    "#         if np.linalg.norm(current_cube_pos - target) < 0.01:\n",
    "#             print(\"Cube lifted successfully!, current_cube_pos:\", current_cube_pos, \", target:\", target, \", current_stage:\", current_stage)\n",
    "#             break\n",
    "\n",
    "#     # Compute simple proportional action in end-effector space\n",
    "#     action = np.zeros(env.action_dim)\n",
    "#     if current_stage <= 2:\n",
    "#         action[:3] = kp * (target - current_eef)  # x,y,z\n",
    "#         action[3:6] = 0.0  # no rotation change\n",
    "#     else:\n",
    "#         action[:3] = kp * (target - current_cube_pos)  # x,y,z\n",
    "#         action[3:6] = 0.0  # no rotation change\n",
    "#     # Gripper control\n",
    "#     if current_stage <= 2:\n",
    "#         action[-1] = -1.0  # open\n",
    "#     else:\n",
    "#         # Gradually close over first gripper_close_steps\n",
    "#         action[-1] = min(1.0, (step_count % gripper_close_steps) / gripper_close_steps)\n",
    "\n",
    "#     # Step environment\n",
    "#     obs, reward, done, info = env.step(action)\n",
    "#     env.render()\n",
    "#     time.sleep(0.01)\n",
    "#     step_count += 1\n",
    "\n",
    "# print(\"cube_pos:\", current_cube_pos, \"current_eef:\", current_eef, \", target:\", target, \", current_stage:\", current_stage)\n",
    "# env.close()\n",
    "# print(\"Simulation finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2afb98",
   "metadata": {},
   "source": [
    "# For macOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2af89a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m[robosuite INFO] \u001b[0mLoading controller configuration from: /opt/miniconda3/envs/mujoco-env/lib/python3.10/site-packages/robosuite/controllers/config/robots/default_panda.json (composite_controller_factory.py:121)\n",
      "\u001b[1m\u001b[32m[robosuite INFO] \u001b[0mLoading controller configuration from: /opt/miniconda3/envs/mujoco-env/lib/python3.10/site-packages/robosuite/controllers/config/robots/default_panda.json (composite_controller_factory.py:121)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cube position: [0.03  0.012 0.831]\n",
      "Above cube target: [0.03  0.012 0.931]\n",
      "Grasp position: [0.03  0.012 0.821]\n",
      "Lift position: [0.03  0.012 1.331]\n",
      "Above cube reached, moving to grasp\n",
      "ready to grasp\n",
      "Cube grasped, lifting\n",
      "Cube lifted successfully!, current_cube_pos: [0.029 0.011 1.321] , target: [0.03  0.012 1.331] , current_stage: 4\n",
      "cube_pos: [0.029 0.011 1.321] current_eef: [0.026 0.012 1.33 ] , target: [0.03  0.012 1.331] , current_stage: 4\n",
      "Simulation finished\n",
      "Video saved!\n"
     ]
    }
   ],
   "source": [
    "import robosuite as suite\n",
    "import numpy as np\n",
    "import imageio\n",
    "\n",
    "# Create environment with Franka rob1t\n",
    "env = suite.make(\n",
    "    env_name=\"Lift\",\n",
    "    robots=\"Panda\",\n",
    "    has_renderer=False,\n",
    "    has_offscreen_renderer=True,\n",
    "    use_camera_obs=False\n",
    ")\n",
    "\n",
    "# Reset the environment\n",
    "obs = env.reset()\n",
    "\n",
    "# Get cube position from observation\n",
    "cube_pos = obs['cube_pos']\n",
    "print(\"Cube position:\", cube_pos)\n",
    "\n",
    "# Define target positions for lifting the cube:\n",
    "# Stage 1: Move above the cube\n",
    "above_cube_pos = cube_pos.copy()\n",
    "above_cube_pos[2] += 0.1  # Position 10cm above the cube\n",
    "\n",
    "# Stage 2: Move down to grasp the cube\n",
    "grasp_pos = cube_pos.copy()\n",
    "grasp_pos[2] -= 0.01  # Move slightly down to grasp\n",
    "\n",
    "# Stage 3: Lift the cube\n",
    "lift_pos = cube_pos.copy()\n",
    "lift_pos[2] += 0.5  # Lift 20cm above the table\n",
    "#lift_pos[0] += 0.5  # Lift 20cm above the table\n",
    "\n",
    "print(f\"Above cube target: {above_cube_pos}\")\n",
    "print(f\"Grasp position: {grasp_pos}\")\n",
    "print(f\"Lift position: {lift_pos}\")\n",
    "\n",
    "# Control gains\n",
    "kp = 5.0  # Position gain\n",
    "gripper_close_steps = 50  # Steps over which to close gripper gradually\n",
    "kd = 1.0  # Velocity gain\n",
    "\n",
    "# Run the simulation\n",
    "done = False\n",
    "step_count = 0\n",
    "max_steps = 500\n",
    "current_stage = 1\n",
    "grasped = False\n",
    "\n",
    "frames = []\n",
    "while step_count < max_steps:\n",
    "    current_eef = obs['robot0_eef_pos']\n",
    "    current_cube_pos = obs['cube_pos']\n",
    "\n",
    "    # Determine target\n",
    "    if current_stage == 1:\n",
    "        target = above_cube_pos\n",
    "        if np.linalg.norm(current_eef - target) < 0.02:\n",
    "            current_stage = 2\n",
    "            print(\"Above cube reached, moving to grasp\")\n",
    "    elif current_stage == 2:\n",
    "        target = grasp_pos\n",
    "        if np.linalg.norm(current_eef - target) < 0.01:\n",
    "            current_stage = 3\n",
    "            print(\"ready to grasp\")\n",
    "    elif current_stage == 3:\n",
    "        target = grasp_pos\n",
    "        if action[-1] > 0.5:\n",
    "            grasped = True\n",
    "        if np.linalg.norm(current_eef - target) < 0.01 and grasped:\n",
    "            current_stage = 4 \n",
    "            print(\"Cube grasped, lifting\")\n",
    "    else:\n",
    "        target = lift_pos\n",
    "        if np.linalg.norm(current_cube_pos - target) < 0.01:\n",
    "            print(\"Cube lifted successfully!, current_cube_pos:\", current_cube_pos, \", target:\", target, \", current_stage:\", current_stage)\n",
    "            break\n",
    "\n",
    "    # Compute simple proportional action in end-effector space\n",
    "    action = np.zeros(env.action_dim)\n",
    "    if current_stage <= 2:\n",
    "        action[:3] = kp * (target - current_eef)  # x,y,z\n",
    "        action[3:6] = 0.0  # no rotation change\n",
    "    else:\n",
    "        action[:3] = kp * (target - current_cube_pos)  # x,y,z\n",
    "        action[3:6] = 0.0  # no rotation change\n",
    "    # Gripper control\n",
    "    if current_stage <= 2:\n",
    "        action[-1] = -1.0  # open\n",
    "    else:\n",
    "        # Gradually close over first gripper_close_steps\n",
    "        action[-1] = min(1.0, (step_count % gripper_close_steps) / gripper_close_steps)\n",
    "\n",
    "    # Step environment\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    # Render offscreen frame\n",
    "    frame = env.sim.render(camera_name=\"frontview\", width=640, height=480)\n",
    "    frame = np.flip(frame, axis=0)\n",
    "    frames.append(frame)\n",
    "\n",
    "    time.sleep(0.01)\n",
    "    step_count += 1\n",
    "\n",
    "print(\"cube_pos:\", current_cube_pos, \"current_eef:\", current_eef, \", target:\", target, \", current_stage:\", current_stage)\n",
    "env.close()\n",
    "print(\"Simulation finished\")\n",
    "imageio.mimwrite(\"lift_cube.mp4\", frames, fps=30)\n",
    "print(\"Video saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf344e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mujoco-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
